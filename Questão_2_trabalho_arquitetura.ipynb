{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Equipe 16 </h1>\n",
        "<ul><li>Ana Beatriz Kindinger</li>\n",
        "<li>Daniel Victor Andrade</li>\n",
        "<li>Igor Buess Atala Y Mansour</li>\n",
        "<li>Marlon Mateus Prudente de Oliveira</li>\n",
        "<li>Ronaldo Santana da Silva Moco</li></ul>\n"
      ],
      "metadata": {
        "id": "abu8dgDTIDFj"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kj_c4RdlbySz"
      },
      "source": [
        "<h1>Atividade 02 - melhorar o desempenho de RP em conjunto de dados existentes</h1>\n",
        "<p>A atividade 02 visa trabalhar com um conjunto de dados pré-construído, onde as opções que o desenvolvedor tem, são de aplicar as técnicas de pré-processamento abaixo relacionadas:</p>\n",
        "<ul><li>Seleção</li>\n",
        "<li>Limpeza</li>\n",
        "<li>Codificação</li>\n",
        "<li>Enriquecimento</li>\n",
        "<li>Normalização</li>\n",
        "<li>Construção de Atributos</li>\n",
        "<li>Correção de Prevalência</li>\n",
        "<li>Partição do Conjunto de Dados</li>\n",
        "</ul>\n",
        "<p>Busque uma base de dados na UCI Machine Learning que seja indicada para problemas de classificação. (<a target=\"_blank\" href=\"https://archive.ics.uci.edu/datasets\">https://archive.ics.uci.edu/datasets</a>)</p>\n",
        "<p>Para esse exemplo, vamos usar a base Secondary Mushroom (https://archive.ics.uci.edu/static/public/848/data.csv)</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n83lcKbzgBnE"
      },
      "source": [
        "Opção 01 - carregando o arquivo de dados da pasta local para o colab.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ZQrA84pEAh0-"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import scale\n",
        "from sklearn.preprocessing import minmax_scale\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "2Avn4baOAh1A",
        "outputId": "8df65e24-fc55-400f-f45a-e6d55910e457"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "  class cap-diameter cap-shape cap-surface cap-color does-bruise-or-bleed  \\\n",
            "1     p        15.26         x           g         o                    f   \n",
            "2     p         16.6         x           g         o                    f   \n",
            "3     p        14.07         x           g         o                    f   \n",
            "4     p        14.17         f           h         e                    f   \n",
            "5     p        14.64         x           h         o                    f   \n",
            "\n",
            "  gill-attachment gill-spacing gill-color stem-height  ... stem-root  \\\n",
            "1               e          NaN          w       16.95  ...         s   \n",
            "2               e          NaN          w       17.99  ...         s   \n",
            "3               e          NaN          w        17.8  ...         s   \n",
            "4               e          NaN          w       15.77  ...         s   \n",
            "5               e          NaN          w       16.53  ...         s   \n",
            "\n",
            "  stem-surface stem-color veil-type veil-color has-ring ring-type  \\\n",
            "1            y          w         u          w        t         g   \n",
            "2            y          w         u          w        t         g   \n",
            "3            y          w         u          w        t         g   \n",
            "4            y          w         u          w        t         p   \n",
            "5            y          w         u          w        t         p   \n",
            "\n",
            "  spore-print-color habitat season  \n",
            "1               NaN       d      w  \n",
            "2               NaN       d      u  \n",
            "3               NaN       d      w  \n",
            "4               NaN       d      w  \n",
            "5               NaN       d      w  \n",
            "\n",
            "[5 rows x 21 columns]\n"
          ]
        }
      ],
      "source": [
        "url = \"https://archive.ics.uci.edu/static/public/848/data.csv\"\n",
        "colunas = [\"class\",\t\"cap-diameter\",\t\"cap-shape\", \"cap-surface\",\t\"cap-color\", \"does-bruise-or-bleed\",\n",
        "           \"gill-attachment\", \"gill-spacing\", \"gill-color\",\t\"stem-height\",\t\"stem-width\", \"stem-root\",\n",
        "           \"stem-surface\",\t\"stem-color\",\t\"veil-type\",\t\"veil-color\",\t\"has-ring\",\t\"ring-type\",\n",
        "           \"spore-print-color\",\t\"habitat\",\t\"season\"]\n",
        "\n",
        "colunas_categoricas = [\t\"cap-shape\", \"cap-surface\",\t\"cap-color\", \"does-bruise-or-bleed\",\n",
        "           \"gill-attachment\", \"gill-spacing\", \"gill-color\", \"stem-root\",\n",
        "           \"stem-surface\",\t\"stem-color\",\t\"veil-type\",\t\"veil-color\",\t\"has-ring\",\t\"ring-type\",\n",
        "           \"spore-print-color\",\t\"habitat\",\t\"season\"]\n",
        "\n",
        "colunas_numericas = [\"cap-diameter\", \"stem-height\",\t\"stem-width\"]\n",
        "\n",
        "sm = pd.read_csv(url, header=None, low_memory=False, names=colunas)\n",
        "sm = sm.drop(index=0)\n",
        "\n",
        "print(type(sm))\n",
        "print(sm.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfN629xbuX-_"
      },
      "source": [
        "<h2>Hora de realizar os tratamentos<h2>\n",
        "<p>no exemplo, iremos normalizar as colunas, remover a coluna de identificação e separar a classe dos atributos.</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "OLrGqcAMulAE",
        "outputId": "cc5d7570-7bb5-417a-b65e-9fb26b67b217"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  cap-diameter stem-height stem-width  cap-shape_b  cap-shape_c  cap-shape_f  \\\n",
            "1        15.26       16.95      17.09        False        False        False   \n",
            "2         16.6       17.99      18.19        False        False        False   \n",
            "3        14.07        17.8      17.74        False        False        False   \n",
            "4        14.17       15.77      15.98        False        False         True   \n",
            "5        14.64       16.53       17.2        False        False        False   \n",
            "\n",
            "   cap-shape_o  cap-shape_p  cap-shape_s  cap-shape_x  ...  habitat_h  \\\n",
            "1        False        False        False         True  ...      False   \n",
            "2        False        False        False         True  ...      False   \n",
            "3        False        False        False         True  ...      False   \n",
            "4        False        False        False        False  ...      False   \n",
            "5        False        False        False         True  ...      False   \n",
            "\n",
            "   habitat_l  habitat_m  habitat_p  habitat_u  habitat_w  season_a  season_s  \\\n",
            "1      False      False      False      False      False     False     False   \n",
            "2      False      False      False      False      False     False     False   \n",
            "3      False      False      False      False      False     False     False   \n",
            "4      False      False      False      False      False     False     False   \n",
            "5      False      False      False      False      False     False     False   \n",
            "\n",
            "   season_u  season_w  \n",
            "1     False      True  \n",
            "2      True     False  \n",
            "3     False      True  \n",
            "4     False      True  \n",
            "5     False      True  \n",
            "\n",
            "[5 rows x 119 columns]\n",
            "['p' 'e']\n"
          ]
        }
      ],
      "source": [
        "sm_dummies = pd.get_dummies(sm[colunas_categoricas])\n",
        "X = pd.concat([sm[colunas_numericas], sm_dummies], axis=1)\n",
        "\n",
        "\n",
        "#X = sm.iloc[:,1:]\n",
        "cols = sm[0:]\n",
        "print(X.head())\n",
        "Y = sm['class']\n",
        "Y_orig = sm['class']\n",
        "print(Y.unique())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9uS7b_5CxTR"
      },
      "source": [
        "Na próxima seção que deverão ser realizada as tentativas de tratamento de dados, visando a melhoria no desempenho do classificador (SVM)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "-Tp4WMMPyuO2",
        "outputId": "6585c981-6c50-4434-c85f-3988d5950aa0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  cap-diameter stem-height stem-width  cap-shape_b  cap-shape_c  cap-shape_f  \\\n",
            "1        15.26       16.95      17.09        False        False        False   \n",
            "2         16.6       17.99      18.19        False        False        False   \n",
            "3        14.07        17.8      17.74        False        False        False   \n",
            "4        14.17       15.77      15.98        False        False         True   \n",
            "5        14.64       16.53       17.2        False        False        False   \n",
            "\n",
            "   cap-shape_o  cap-shape_p  cap-shape_s  cap-shape_x  ...  habitat_h  \\\n",
            "1        False        False        False         True  ...      False   \n",
            "2        False        False        False         True  ...      False   \n",
            "3        False        False        False         True  ...      False   \n",
            "4        False        False        False        False  ...      False   \n",
            "5        False        False        False         True  ...      False   \n",
            "\n",
            "   habitat_l  habitat_m  habitat_p  habitat_u  habitat_w  season_a  season_s  \\\n",
            "1      False      False      False      False      False     False     False   \n",
            "2      False      False      False      False      False     False     False   \n",
            "3      False      False      False      False      False     False     False   \n",
            "4      False      False      False      False      False     False     False   \n",
            "5      False      False      False      False      False     False     False   \n",
            "\n",
            "   season_u  season_w  \n",
            "1     False      True  \n",
            "2      True     False  \n",
            "3     False      True  \n",
            "4     False      True  \n",
            "5     False      True  \n",
            "\n",
            "[5 rows x 119 columns]\n",
            "['p' 'e']\n",
            "  cap-diameter stem-height stem-width  cap-shape_b  cap-shape_c  cap-shape_f  \\\n",
            "1        15.26       16.95      17.09        False        False        False   \n",
            "2         16.6       17.99      18.19        False        False        False   \n",
            "3        14.07        17.8      17.74        False        False        False   \n",
            "4        14.17       15.77      15.98        False        False         True   \n",
            "5        14.64       16.53       17.2        False        False        False   \n",
            "\n",
            "   cap-shape_o  cap-shape_p  cap-shape_s  cap-shape_x  ...  habitat_h  \\\n",
            "1        False        False        False         True  ...      False   \n",
            "2        False        False        False         True  ...      False   \n",
            "3        False        False        False         True  ...      False   \n",
            "4        False        False        False        False  ...      False   \n",
            "5        False        False        False         True  ...      False   \n",
            "\n",
            "   habitat_l  habitat_m  habitat_p  habitat_u  habitat_w  season_a  season_s  \\\n",
            "1      False      False      False      False      False     False     False   \n",
            "2      False      False      False      False      False     False     False   \n",
            "3      False      False      False      False      False     False     False   \n",
            "4      False      False      False      False      False     False     False   \n",
            "5      False      False      False      False      False     False     False   \n",
            "\n",
            "   season_u  season_w  \n",
            "1     False      True  \n",
            "2      True     False  \n",
            "3     False      True  \n",
            "4     False      True  \n",
            "5     False      True  \n",
            "\n",
            "[5 rows x 119 columns]\n",
            "        0         1         2    3    4    5    6    7    8    9    ...  109  \\\n",
            "0  0.240155  0.499705  0.164469  0.0  0.0  0.0  0.0  0.0  0.0  1.0  ...  0.0   \n",
            "1  0.261782  0.530366  0.175055  0.0  0.0  0.0  0.0  0.0  0.0  1.0  ...  0.0   \n",
            "2  0.220949  0.524764  0.170725  0.0  0.0  0.0  0.0  0.0  0.0  1.0  ...  0.0   \n",
            "3  0.222563  0.464917  0.153787  0.0  0.0  1.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
            "4  0.230148  0.487323  0.165528  0.0  0.0  0.0  0.0  0.0  0.0  1.0  ...  0.0   \n",
            "\n",
            "   110  111  112  113  114  115  116  117  118  \n",
            "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  \n",
            "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  \n",
            "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  \n",
            "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  \n",
            "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  \n",
            "\n",
            "[5 rows x 119 columns]\n"
          ]
        }
      ],
      "source": [
        "X_orig =  X.copy()\n",
        "print(X_orig.head())\n",
        "\n",
        "print(Y_orig.unique() )\n",
        "\n",
        "# normalização min-max\n",
        "X = pd.DataFrame( minmax_scale(X) )\n",
        "\n",
        "#retirada de dados faltantes\n",
        "\n",
        "X.dropna(axis = 1, how ='any')\n",
        "\n",
        "print(X_orig.head())\n",
        "print(X.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBZUGabt2eZv"
      },
      "source": [
        "A próxima seção trata da construção do modelo, dos testes e das métricas da matriz de confusão."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "hDFNHGyF20UV"
      },
      "outputs": [],
      "source": [
        "# com os dados originais\n",
        "X_oring_train, X_orig_test, y_orig_train, y_orig_test = train_test_split(X_orig,\n",
        "                      Y_orig, test_size=0.25, stratify=Y_orig,random_state=10)\n",
        "\n",
        "# com os dados tratados\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25,\n",
        "                                                    stratify=Y,random_state=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsF5IaEU49xG"
      },
      "source": [
        "Treina o modelo com base nos dados originais (SVM)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "1xyxTe-q49T_",
        "outputId": "3a7e6484-55cb-4321-b9e4-1b88c498e8c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia nos dados de treinamento ORIGINAIS: 95.03%\n",
            "Matriz de confusão - com os dados ORIGINAIS usados no TREINAMENTO\n",
            "[[19080  1305]\n",
            " [  970 24446]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           e       0.95      0.94      0.94     20385\n",
            "           p       0.95      0.96      0.96     25416\n",
            "\n",
            "    accuracy                           0.95     45801\n",
            "   macro avg       0.95      0.95      0.95     45801\n",
            "weighted avg       0.95      0.95      0.95     45801\n",
            "\n",
            "Matriz de confusão - com os dados ORIGINAIS usados para TESTES\n",
            "[[6274  522]\n",
            " [ 327 8145]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           e       0.95      0.92      0.94      6796\n",
            "           p       0.94      0.96      0.95      8472\n",
            "\n",
            "    accuracy                           0.94     15268\n",
            "   macro avg       0.95      0.94      0.94     15268\n",
            "weighted avg       0.94      0.94      0.94     15268\n",
            "\n"
          ]
        }
      ],
      "source": [
        "treinador = svm.SVC()  #algoritmo escolhido\n",
        "\n",
        "modelo_orig = treinador.fit(X_oring_train, y_orig_train)\n",
        "\n",
        "# score com os dados de treinamento\n",
        "acuracia_orig = modelo_orig.score(X_oring_train, y_orig_train)\n",
        "print(\"Acurácia nos dados de treinamento ORIGINAIS: {:.2f}%\".format(acuracia_orig * 100))\n",
        "\n",
        "# predição com os mesmos dados usados para treinar\n",
        "y_orig_pred = modelo_orig.predict(X_oring_train)\n",
        "cm_orig_train = confusion_matrix(y_orig_train, y_orig_pred)\n",
        "print('Matriz de confusão - com os dados ORIGINAIS usados no TREINAMENTO')\n",
        "print(cm_orig_train)\n",
        "print(classification_report(y_orig_train, y_orig_pred))\n",
        "\n",
        "# predição com os mesmos dados usados para testar\n",
        "print('Matriz de confusão - com os dados ORIGINAIS usados para TESTES')\n",
        "y2_orig_pred = modelo_orig.predict(X_orig_test)\n",
        "cm_orig_test = confusion_matrix(y_orig_test, y2_orig_pred)\n",
        "print(cm_orig_test)\n",
        "print(classification_report(y_orig_test, y2_orig_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PdacgFz9mX3"
      },
      "source": [
        "Como os dados ficam após os processos de tratamento dos dados?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "mOeKrnRB9rU_",
        "outputId": "545fc50b-cc30-4853-a490-676c838ae269"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia nos dados de treinamento TRATADOS: 99.96%\n",
            "Matriz de confusão - com os dados TRATADOS usados no TREINAMENTO\n",
            "[[20368    17]\n",
            " [    3 25413]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           e       1.00      1.00      1.00     20385\n",
            "           p       1.00      1.00      1.00     25416\n",
            "\n",
            "    accuracy                           1.00     45801\n",
            "   macro avg       1.00      1.00      1.00     45801\n",
            "weighted avg       1.00      1.00      1.00     45801\n",
            "\n",
            "Matriz de confusão - com os dados TRATADOS usados para TESTES\n",
            "[[6795    1]\n",
            " [   3 8469]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           e       1.00      1.00      1.00      6796\n",
            "           p       1.00      1.00      1.00      8472\n",
            "\n",
            "    accuracy                           1.00     15268\n",
            "   macro avg       1.00      1.00      1.00     15268\n",
            "weighted avg       1.00      1.00      1.00     15268\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn import svm\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "treinador = svm.SVC()  #algoritmo escolhido\n",
        "\n",
        "modelo = treinador.fit(X_train, y_train)\n",
        "\n",
        "# score com os dados de treinamento\n",
        "acuracia = modelo.score(X_train, y_train)\n",
        "print(\"Acurácia nos dados de treinamento TRATADOS: {:.2f}%\".format(acuracia * 100))\n",
        "\n",
        "# predição com os mesmos dados usados para treinar\n",
        "y_pred = modelo.predict(X_train)\n",
        "cm_train = confusion_matrix(y_train, y_pred)\n",
        "print('Matriz de confusão - com os dados TRATADOS usados no TREINAMENTO')\n",
        "print(cm_train)\n",
        "print(classification_report(y_train, y_pred))\n",
        "\n",
        "# predição com os mesmos dados usados para testar\n",
        "print('Matriz de confusão - com os dados TRATADOS usados para TESTES')\n",
        "y2_pred = modelo.predict(X_test)\n",
        "cm_test = confusion_matrix(y_test, y2_pred)\n",
        "print(cm_test)\n",
        "print(classification_report(y_test, y2_pred))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}